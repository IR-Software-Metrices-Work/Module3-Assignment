{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e87d62",
   "metadata": {},
   "source": [
    "# Module #3 -- Assignment\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Using all the knowledge acquired mainly in this module to create a cli entry retrieval of the job description data used up to the current module.\n",
    "\n",
    "- The entry retrieval retrieved query via command line and the entry can be of any range.\n",
    "- Use n-gram where n=1 and 2.\n",
    "- Only top 5 ranks are needed to be displayed to the users.\n",
    "- For the others, you can design by yourself.\n",
    "\n",
    "## Your task \n",
    "\n",
    "explore the three variants of ranking methods:\n",
    "\n",
    "- Rank using only tf\n",
    "- Rank using both tf and idf\n",
    "- Rank using BM25\n",
    "\n",
    "`Please also discuss the different in the returned ranks.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2442e9bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd684e5",
   "metadata": {},
   "source": [
    "# Module Preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68592003",
   "metadata": {},
   "source": [
    "## The essential python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde3909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd # do some data\n",
    "import string\n",
    "import timeit # just import for timer\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # tf-idf built in function\n",
    "from scipy import sparse\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705f7bc2",
   "metadata": {},
   "source": [
    "## The Code or Class that going to use in this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe5ce75",
   "metadata": {},
   "source": [
    "### Get Data from .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42ecdf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_data():\n",
    "    data = pd.read_csv('./data/software_developer_united_states_1971_20191023_1.csv')\n",
    "    description = data['job_description']\n",
    "    cleaned_description = description.apply(lambda s: s.translate(str.maketrans('', '', string.punctuation + u'\\xa0')))\n",
    "    cleaned_description = cleaned_description.apply(lambda s: s.lower())\n",
    "    cleaned_description = cleaned_description.apply(lambda s: s.translate(str.maketrans(string.whitespace, ' '*len(string.whitespace), '')))\n",
    "    cleaned_description = cleaned_description.drop_duplicates()\n",
    "    return cleaned_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cf09fe",
   "metadata": {},
   "source": [
    "### Setup pre process for faster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de8db0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(s):\n",
    "    ps = PorterStemmer()\n",
    "    s = word_tokenize(s)\n",
    "    stopwords_set = set(stopwords.words())\n",
    "    stop_dict = {s: 1 for s in stopwords_set}\n",
    "    s = [w for w in s if w not in stop_dict]\n",
    "    s = [ps.stem(w) for w in s]\n",
    "    s = ' '.join(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6510b3",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2983be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25(object):\n",
    "    def __init__(self, b=0.75, k1=1.6):\n",
    "        self.vectorizer = TfidfVectorizer(norm=None, smooth_idf=False)\n",
    "        self.b = b\n",
    "        self.k1 = k1\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.vectorizer.fit(X)\n",
    "        y = super(TfidfVectorizer, self.vectorizer).transform(X)\n",
    "        self.avdl = y.sum(1).mean()\n",
    "\n",
    "    def transform(self, q, X):\n",
    "        b, k1, avdl = self.b, self.k1, self.avdl\n",
    "\n",
    "        X = super(TfidfVectorizer, self.vectorizer).transform(X)\n",
    "        len_X = X.sum(1).A1\n",
    "        q, = super(TfidfVectorizer, self.vectorizer).transform([q])\n",
    "        assert sparse.isspmatrix_csr(q)\n",
    "\n",
    "        X = X.tocsc()[:, q.indices]\n",
    "        denom = X + (k1 * (1 - b + b * len_X / avdl))[:, None]\n",
    "        idf = self.vectorizer._tfidf.idf_[None, q.indices] - 1.\n",
    "        numer = X.multiply(np.broadcast_to(idf, X.shape)) * (k1 + 1)                                                          \n",
    "        return (numer / denom).sum(1).A1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a22f1f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85475e12",
   "metadata": {},
   "source": [
    "# Assignment Part\n",
    "\n",
    "explore the three variants of ranking methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b97889",
   "metadata": {},
   "source": [
    "## Rank using only tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af9d073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some cool python code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe48cf55",
   "metadata": {},
   "source": [
    "## Rank using both tf and idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "409ba731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another cool python code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d882ca9",
   "metadata": {},
   "source": [
    "## Rank using BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "369bc84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# very super duper coolest python code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b5c960",
   "metadata": {},
   "source": [
    "## Some conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d42538e",
   "metadata": {},
   "source": [
    "- Bra Bra Bra\n",
    "- Bra Bra Bra\n",
    "- Bra Bra?\n",
    "- Bra Bra\n",
    "- Bruh.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604ea5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
