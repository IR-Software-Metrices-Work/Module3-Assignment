{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e87d62",
   "metadata": {},
   "source": [
    "# Module #3 -- Assignment\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Using all the knowledge acquired mainly in this module to create a cli entry retrieval of the job description data used up to the current module.\n",
    "\n",
    "- The entry retrieval retrieved query via command line and the entry can be of any range.\n",
    "- Use n-gram where n=1 and 2.\n",
    "- Only top 5 ranks are needed to be displayed to the users.\n",
    "- For the others, you can design by yourself.\n",
    "\n",
    "## Your task \n",
    "\n",
    "explore the three variants of ranking methods:\n",
    "\n",
    "- Rank using only tf\n",
    "- Rank using both tf and idf\n",
    "- Rank using BM25\n",
    "\n",
    "`Please also discuss the different in the returned ranks.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2442e9bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd684e5",
   "metadata": {},
   "source": [
    "# Module Preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68592003",
   "metadata": {},
   "source": [
    "## The essential python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde3909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd # do some data\n",
    "import string\n",
    "import timeit # just import for timer\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # tf-idf built in function\n",
    "from scipy import sparse\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705f7bc2",
   "metadata": {},
   "source": [
    "## The Code or Class that going to use in this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe5ce75",
   "metadata": {},
   "source": [
    "### Get Data from .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ecdf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_data():\n",
    "    data = pd.read_csv('./data/software_developer_united_states_1971_20191023_1.csv')\n",
    "    description = data['job_description']\n",
    "    cleaned_description = description.apply(lambda s: s.translate(str.maketrans('', '', string.punctuation + u'\\xa0')))\n",
    "    cleaned_description = cleaned_description.apply(lambda s: s.lower())\n",
    "    cleaned_description = cleaned_description.apply(lambda s: s.translate(str.maketrans(string.whitespace, ' '*len(string.whitespace), '')))\n",
    "    cleaned_description = cleaned_description.drop_duplicates()\n",
    "    return cleaned_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cf09fe",
   "metadata": {},
   "source": [
    "### Setup pre process for faster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de8db0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(s):\n",
    "    ps = PorterStemmer()\n",
    "    s = word_tokenize(s)\n",
    "    stopwords_set = set(stopwords.words())\n",
    "    stop_dict = {s: 1 for s in stopwords_set}\n",
    "    s = [w for w in s if w not in stop_dict]\n",
    "    s = [ps.stem(w) for w in s]\n",
    "    s = ' '.join(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6510b3",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2983be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25(object):\n",
    "    def __init__(self, b=0.75, k1=1.6):\n",
    "        self.vectorizer = TfidfVectorizer(norm=None, smooth_idf=False)\n",
    "        self.b = b\n",
    "        self.k1 = k1\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.vectorizer.fit(X)\n",
    "        y = super(TfidfVectorizer, self.vectorizer).transform(X)\n",
    "        self.avdl = y.sum(1).mean()\n",
    "\n",
    "    def transform(self, q, X):\n",
    "        b, k1, avdl = self.b, self.k1, self.avdl\n",
    "\n",
    "        X = super(TfidfVectorizer, self.vectorizer).transform(X)\n",
    "        len_X = X.sum(1).A1\n",
    "        q, = super(TfidfVectorizer, self.vectorizer).transform([q])\n",
    "        assert sparse.isspmatrix_csr(q)\n",
    "\n",
    "        X = X.tocsc()[:, q.indices]\n",
    "        denom = X + (k1 * (1 - b + b * len_X / avdl))[:, None]\n",
    "        idf = self.vectorizer._tfidf.idf_[None, q.indices] - 1.\n",
    "        numer = X.multiply(np.broadcast_to(idf, X.shape)) * (k1 + 1)\n",
    "        \n",
    "        return (numer / denom).sum(1).A1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a22f1f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbd601f",
   "metadata": {},
   "source": [
    "# CLI Entry Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782bd348",
   "metadata": {},
   "source": [
    "## Client CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e17a66e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are you looking for : java aws azure docker python\n"
     ]
    }
   ],
   "source": [
    "job_entry = input(\"What are you looking for : \").split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8a691d",
   "metadata": {},
   "source": [
    "## Simple Dictaionary Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29b4a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_five(key_word):\n",
    "    result = dict()\n",
    "    key_word_dict = key_word.to_dict()\n",
    "    \n",
    "    for item in key_word_dict:\n",
    "        result[item] = key_word_dict[item][0]\n",
    "        for index in key_word_dict[item] :\n",
    "            result[item] += key_word_dict[item][index]\n",
    "            \n",
    "    return sorted(result.items(), key=lambda x: x[1], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b103a2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85475e12",
   "metadata": {},
   "source": [
    "# Assignment Part\n",
    "\n",
    "explore the three variants of ranking methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3454de",
   "metadata": {},
   "source": [
    "## Information Retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ff56ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x19135 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 38929 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_description = get_and_clean_data()\n",
    "cleaned_description = cleaned_description.iloc[:100]\n",
    "\n",
    "vectorizer = CountVectorizer(preprocessor=preProcess, ngram_range=(1, 2))\n",
    "vectorizer.fit_transform(cleaned_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b97889",
   "metadata": {},
   "source": [
    "## Rank using only tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af9d073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_ranking():\n",
    "    X = vectorizer.transform(job_entry)\n",
    "    \n",
    "    # tf formula\n",
    "    X.data = np.log10(X.data + 1)\n",
    "    tf = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    print(show_top_five(tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60515368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('java', 0.6020599913279624), ('aw', 0.3010299956639812), ('azur', 0.3010299956639812), ('docker', 0.3010299956639812), ('python', 0.3010299956639812)]\n"
     ]
    }
   ],
   "source": [
    "tf_ranking()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe48cf55",
   "metadata": {},
   "source": [
    "## Rank using both tf and idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "409ba731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_ranking(n):\n",
    "    X = vectorizer.transform(job_entry)\n",
    "    \n",
    "    # tf-idf formula\n",
    "    idf = n / (X.tocoo() > 0).sum(0)\n",
    "    X.data = np.log10(X.data + 1)\n",
    "    X.data = X.multiply(np.log10(idf))\n",
    "    \n",
    "    tfidf = pd.DataFrame(X.data.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    print(show_top_five(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6071e81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp/ipykernel_17216/2407125988.py:5: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = n / (X.tocoo() > 0).sum(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('java', 0.42082187474904936), ('aw', 0.21041093737452468), ('azur', 0.21041093737452468), ('docker', 0.21041093737452468), ('python', 0.21041093737452468)]\n"
     ]
    }
   ],
   "source": [
    "tf_idf_ranking(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d882ca9",
   "metadata": {},
   "source": [
    "## Rank using BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "369bc84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "def BM25_ranking():\n",
    "    bm25 = BM25()\n",
    "    bm_ranking = bm25.fit(cleaned_description)\n",
    "    bm_ranking = bm25.transform(' '.join(w for w in job_entry), cleaned_description)\n",
    "    \n",
    "    pprint(sorted(bm_ranking, reverse=True)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5cb1be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.53906968182736,\n",
      " 8.01630235443384,\n",
      " 6.114675079756328,\n",
      " 5.395575450169901,\n",
      " 5.342448261012892]\n"
     ]
    }
   ],
   "source": [
    "BM25_ranking()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b5c960",
   "metadata": {},
   "source": [
    "## My Though about This assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d42538e",
   "metadata": {},
   "source": [
    "### The result from TF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d5fbc9",
   "metadata": {},
   "source": [
    "term frequency is a technique that retrive information by number of times that the word is occurs in that information \n",
    "\n",
    ",because of Java is occurs the most in the document that why java have the high place in the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbad66d",
   "metadata": {},
   "source": [
    "### The result from TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1158c1af",
   "metadata": {},
   "source": [
    "term frequency Inversion document frequency is use the weight and the weight is calculate from the word counting\n",
    "\n",
    "java seem happen to appear in the individual word without any term as prefix or postfix that why it also have the highest place while using the tf-idf technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787c03c5",
   "metadata": {},
   "source": [
    "### The result from BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e61276",
   "metadata": {},
   "source": [
    "BM25 is a Best Match 25 it is a standard way using the probabilitstic IR model it using a bag of word to calculate and using the binomial distribution to do as a result\n",
    "\n",
    "because I cannot turn the np.ndarray to show in the pandas data frame I will assume that java will place to top place ( 8.xxx) because this word seem to seperate all over the .csv data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5654a2",
   "metadata": {},
   "source": [
    "ended assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67135320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
